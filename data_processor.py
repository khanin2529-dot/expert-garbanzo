# -*- coding: utf-8 -*-
"""
Data Processor - ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
"""

import logging
import json
import csv
from pathlib import Path
from datetime import datetime

logger = logging.getLogger(__name__)


class DataProcessor:
    """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"""
    
    def __init__(self, input_dir, output_dir):
        """
        Args:
            input_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï
            output_dir: ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def process_csv(self, filepath):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• CSV"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                data = list(reader)
            
            logger.info(f"‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• CSV: {Path(filepath).name} ({len(data)} ‡πÅ‡∏ñ‡∏ß)")
            return {
                'type': 'csv',
                'file': Path(filepath).name,
                'rows': len(data),
                'columns': list(reader.fieldnames) if reader.fieldnames else []
            }
        
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return None
    
    def process_json(self, filepath):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• JSON"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• JSON: {Path(filepath).name}")
            return {
                'type': 'json',
                'file': Path(filepath).name,
                'keys': list(data.keys()) if isinstance(data, dict) else 'array',
                'size': len(data) if isinstance(data, (dict, list)) else 1
            }
        
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return None
    
    def process_text(self, filepath):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            words = content.split()
            
            logger.info(f"‚úì ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• Text: {Path(filepath).name}")
            return {
                'type': 'text',
                'file': Path(filepath).name,
                'lines': len(lines),
                'words': len(words),
                'characters': len(content)
            }
        
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return None
    
    def process_file(self, filepath):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó"""
        filepath = Path(filepath)
        extension = filepath.suffix.lower()
        
        if extension == '.csv':
            return self.process_csv(filepath)
        elif extension == '.json':
            return self.process_json(filepath)
        elif extension in ['.txt', '.log']:
            return self.process_text(filepath)
        else:
            logger.warning(f"‚ö†Ô∏è ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏£‡∏±‡∏ö‡∏£‡∏≠‡∏á: {extension}")
            return None
    
    def batch_process(self, file_list):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå"""
        results = []
        
        for file_path in file_list:
            result = self.process_file(file_path)
            if result:
                results.append(result)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = self.output_dir / f"report_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'total_files': len(results),
                'results': results
            }, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìä ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô: {output_file.name}")
        return results
    
    def generate_summary(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
        try:
            input_files = list(self.input_dir.rglob('*'))
            output_files = list(self.output_dir.rglob('*'))
            
            summary = {
                'timestamp': datetime.now().isoformat(),
                'input_files': len([f for f in input_files if f.is_file()]),
                'output_files': len([f for f in output_files if f.is_file()]),
                'input_size': sum(f.stat().st_size for f in input_files if f.is_file()),
                'output_size': sum(f.stat().st_size for f in output_files if f.is_file())
            }
            
            logger.info(f"üìà ‡∏™‡∏£‡∏∏‡∏õ: {summary['input_files']} ‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï, {summary['output_files']} ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏≤‡∏ï‡πå‡∏û‡∏∏‡∏ï")
            return summary
        
        except Exception as e:
            logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
            return None


def validate_data(data):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        if not data:
            logger.warning("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡πà‡∏≤‡∏á")
            return False
        
        logger.info(f"‚úì ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡πà‡∏≤‡∏ô")
        return True
    
    except Exception as e:
        logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return False


def export_data(data, output_file, format='json'):
    """‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        elif format == 'csv' and isinstance(data, list):
            if data:
                with open(output_path, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=data[0].keys())
                    writer.writeheader()
                    writer.writerows(data)
        
        logger.info(f"‚úì ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {output_path.name}")
        return True
    
    except Exception as e:
        logger.error(f"‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return False
